# ============================================================================
# Z-Explorer Configuration
# ============================================================================
# Copy this file to .env and customize as needed.
# The setup wizard (z-explorer --setup) can also create this for you.
#
# Run `uv run z-explorer --show-config` to verify your configuration.
# ============================================================================


# ============================================================================
# IMAGE MODEL CONFIGURATION (Z-Image-Turbo)
# ============================================================================

# Loading mode for the image generation model.
# Options:
#   - sdnq        : SDNQ quantized model (~6GB download, ~12GB VRAM) [RECOMMENDED]
#   - hf_download : Download full model from HuggingFace (~15GB, ~24GB VRAM)
#   - hf_local    : Use a local HuggingFace model directory
#   - components  : Use individual safetensor files (ComfyUI-style)
#
Z_IMAGE_MODE=sdnq

# --- SDNQ Mode (default, recommended for 12GB GPUs) ---
# SDNQ quantized model repository
# Default: Disty0/Z-Image-Turbo-SDNQ-uint4-svd-r32
#
# Z_IMAGE_SDNQ=Disty0/Z-Image-Turbo-SDNQ-uint4-svd-r32

# --- HF Download Mode (full quality, 24GB+ VRAM) ---
# Downloads from: Tongyi-MAI/Z-Image-Turbo
# No additional configuration needed.

# --- HF Local Mode (offline use) ---
# Path to a local clone of the HuggingFace repository.
# Must contain model_index.json
#
# Z_IMAGE_HF=/path/to/local/Z-Image-Turbo

# --- Components Mode (ComfyUI-style safetensors) ---
# Use individual safetensor files from your existing setup.
#
# Z_IMAGE_TRANSFORMER=/path/to/transformer.safetensors
# Z_IMAGE_TEXT_ENCODER=/path/to/text_encoder.safetensors
# Z_IMAGE_VAE=/path/to/vae.safetensors


# ============================================================================
# LLM CONFIGURATION (for prompt enhancement & variable generation)
# ============================================================================

# Loading mode for the LLM.
# Options:
#   - hf_download : Download from HuggingFace (supports BNB quantized models!)
#   - z_image     : Use Z-Image's built-in text encoder (slower, no extra download)
#   - hf_local    : Use a local HuggingFace model directory
#   - gguf        : Load from GGUF file (CPU-friendly quantization)
#
LLM_MODE=hf_download

# --- HF Download Mode (recommended) ---
# HuggingFace repository for the LLM.
# Default: unsloth/Qwen3-4B-Instruct-2507-bnb-4bit (BNB 4-bit, fast inference)
# Alternative: Qwen/Qwen3-4B (full precision, more VRAM)
#
LLM_REPO=unsloth/Qwen3-4B-Instruct-2507-bnb-4bit

# --- Z-Image Mode ---
# Uses Z-Image's text encoder (Qwen with "thinking" mode).
# Slower for variable generation but no extra download needed.
# No additional configuration needed.

# --- HF Local Mode ---
# Path to a local HuggingFace model directory.
#
# LLM_PATH=/path/to/local/Qwen3-4B

# --- GGUF Mode (CPU-friendly) ---
# For running on CPU or low-VRAM setups.
#
# LLM_PATH=/path/to/gguf/repo/or/directory
# LLM_GGUF_FILE=model-Q4_K_M.gguf


# ============================================================================
# OUTPUT & CACHE CONFIGURATION
# ============================================================================

# Directory where generated images are saved.
# Default: ./output (relative to where you run z-explorer)
#
# LOCAL_OUTPUT_DIR=./output

# HuggingFace cache directory (for downloaded models).
# Default: ~/.cache/huggingface
#
# HF_HOME=~/.cache/huggingface


# ============================================================================
# EXAMPLE CONFIGURATIONS
# ============================================================================

# --- Quick Start (12GB VRAM) ---
# Z_IMAGE_MODE=sdnq
# LLM_MODE=hf_download
# LLM_REPO=unsloth/Qwen3-4B-Instruct-2507-bnb-4bit

# --- Full Quality (24GB+ VRAM) ---
# Z_IMAGE_MODE=hf_download
# LLM_MODE=z_image

# --- Offline Mode (pre-downloaded models) ---
# Z_IMAGE_MODE=hf_local
# Z_IMAGE_HF=/home/user/models/Z-Image-Turbo
# LLM_MODE=hf_local
# LLM_PATH=/home/user/models/Qwen3-4B

# --- ComfyUI Integration (use existing safetensors) ---
# Z_IMAGE_MODE=components
# Z_IMAGE_TRANSFORMER=/home/user/ComfyUI/models/z-image/transformer.safetensors
# Z_IMAGE_TEXT_ENCODER=/home/user/ComfyUI/models/z-image/text_encoder.safetensors
# Z_IMAGE_VAE=/home/user/ComfyUI/models/z-image/vae.safetensors
# LLM_MODE=gguf
# LLM_PATH=/home/user/ComfyUI/models/llm
# LLM_GGUF_FILE=qwen3-4b-q4_k_m.gguf

